## 推荐系统可解释性

相比与传统的推荐系统，可解释系统不仅能够提升系统透明度，还能够提高用户对系统的信任和接受程度 、用户选择体验推荐产品的概率以及用户满意程度等等，让容易用户购买推荐产品

#### 相关方法

#### Neural Network

推荐系统任务被转化为预测，将user和item相关的特征作为输入，能获得他们的候选以及分数。

##### Tree-enhanced Embedding Model

协同过滤利用user和item的特征实现推荐，然而，这些高维特征不可解释。而基于的决策树分类器其通过特征的选择实现分类或回归，其本身具有较强的可解释性如图所示，因此很自然的想法是利用决策树的选择特征训练网络实现推荐。进行特征筛选，然后将所得特征以及user、itme ids进行Embedding送入至网络，同时结合attention机制（考虑到不同的用户关注item的不同方面）得到推荐结果，具有可解释。

![img](https://pic3.zhimg.com/v2-7b23b01294983b77088a69e913d4c702_r.jpg)

##### RBM for CF

基于RBM的推荐系统（模型的输入为user和item的feature embedding，而output则是不同用户针对不同item的prediction scores），其缺乏可解释性，而CF（协同过滤：一般是在海量的用户中发掘出一小部分和你品位比较类似的，过程中，这些用户成为邻居，然后根据他们喜欢的其他东西组织成一个排序的目录作为推荐给你）相较于RBM有一定的可解释性但是精度较低。因此将CF和RBM相结合，ehonoush (Behnoush et al, 2016)则将CF的results，即用户neighbors的item's score和movie rating输入至RBM中去得到recommendation scores

#### Probability Graphic Model

用户的购买行为一般由许多潜在因素（latent factor）所决定，而这些latent factor又时常耦合在一起，因此我们可以利用概率图模型建模，通过挖掘潜在变量间的相互关系得到最终的prediction，同时使得推荐可解释。

##### Sentiment-Aspect-Region model

概率图模型的一大优点是能够较为方便的引入新的变量即外部特征，同时能够较为清楚的表示变量间的相关关系，这也使得auxiliary information的融入更加容易。Zhao (Zhao et al, 2015)提出SAR模型，该模型通过结合同一时间的sentiment-aspect-region、基于review以及item类别的user preference和地理位置信息建立概率图模型，计算score同时进行推荐

##### Aspect-based Latent Factor Model

这篇文章中作者(Lin et al, 2016)分别从user和item的角度充分挖掘评论信息，同时使用概率图模型进行推荐。与LFM相比，该工作主要涉及三个latent factor：（1）user-review matrix，其中的每一个元素为用户评论中的词频，其可以一定程度上反应该item的类别；（2）item-attribute matrix，其主要由item-property matrix（反映products某些特殊的aspect的受关注程度）和item-quality matrix（通过统计review中positive和negative words的数量来反映item的质量）；（3）rating matrix。通过上述三个matrix预测最终的点击率。

#### Matrix Factorization

矩阵分解技术主要是基于neighborhood的CF模型，即相似的人会喜欢相似的物品或相似的物品会被相似的人喜欢。因此我们可以基于用户的历史行为数据选择最相似的前 N 个item，以推荐给相似的人。例如，user A like item a, and user B is similar to user A, then user B is more likely to like item a等等

是利用user-item的历史行为数据所构成的matrix进行推荐，主要思想是将一个高维、稀疏的user-item matrix分解为两个分别代表user和item潜在特征的稠密的小矩阵表示。同时在矩阵的学习构造过程中我们可以引入外部信息、先验知识实现可解释性推荐。如图1所示。我们可以利用矩阵分解技术去预测user u 对item i 的preference， r^ui ，如式(1)：式中 pu,k 和 qi,k 即为user和item的latent representation

![屏幕截图 2022-10-04 135002](C:\Users\wangkui\Desktop\推荐系统\可解释性\屏幕截图 2022-10-04 135002.png)

 λ(||pu||2+||qi||2) 即为正则化项。同时我们可以在正则化项和目标函数中融入更多的数据、信息以提高模型的准确率和可解释性

主要思想是将一个高维、稀疏的user-item matrix分解为两个分别代表user和item潜在特征的稠密的小矩阵表示。同时在矩阵的学习构造过程中我们可以引入外部信息、先验知识实现可解释性推荐。

##### Overlapping Co-clustering Model

传统的MF技术仅将一个user-item matrix分解为两个矩阵表示，即进行一次分解，将每一个item对应至一个specific class中。但是考虑到每一个item将包含不同层面的attributes，同时每一个用户也不单单尽关注item的某一个aspects，故Thus Reinhard (Reinhard et al, 2017)提出利用 overlapping co-clustering实现推荐，该模型同过指定class or cluste的数目，也即矩阵分解的次数，可以实现将同一item分配至不同的类别中。

#### Graphic Model

与概率图模型不同的是，图模型利用节点和边分别表示实体和实体间的关系，对于推荐系统user、item即可以认为实体，利用attributes间的关系建立实体连接，同时也可以利用用户的消费行为建立图模型

item的attributes间其天生就具有某种联系，可以基于知识图谱和图论中的相关算法去挖掘其间的联系

**A Social Explanation System**

社交数据也可以被用于推荐系统中，指用户之间普遍存在的社交关系，可构成同质图。社交信息的融入在一定程度上增加了用户的可解释性。



## 图学习 推荐系统

### 随机游走：

可以捕获图上各类实体的高阶关系、交互传播、隐式偏好等建模，缺点是效率低，且缺乏用于优化推荐目标的模型参数。

基本思路是从一个结点出发，以预定的概率向其邻居结点前进，前进过程中的路径序列纪录下来，作为该结点的信息以表达该结点，从而为推荐模型建模，预测当前结点最有可能前往的结点作为推荐列表。

缺点：没有用户（结点）每走一步都需要生成所有候选项的排名分值，效率较低；

不像大多数基于学习的范式，随机游走是基于启发式的（heuristic-based），缺乏模型参数来优化模型参数。

### 图表示学习：

该方法将图上每个结点映射为一个低维嵌入向量，以表达图结构信息。根据所使用的嵌入方法不同，可以分为3类：

#### 基于图因式分解的推荐系统（Graph Factorization based RS (GFRS)）

  该方法首先对图上基于元路径（meta-path）的结点交互矩阵进行因式分解（factorization），得到每个结点的embedding，然后将他们作为后续推荐任务的输入。这种方法是可以处理异质图的，捕获不同种类的结点之间的关系信息，如用户、产品。优点：简单高效。缺点：容易受到观测数据稀疏性的影响。

#### 基于图分布表示的推荐系统（Graph Distributed Representation based RS (GDRS)）

  GDRRSs通常遵循Skip-gram模型。Skip-gram模型源自论文《Distributed representations of
words and phrases and their compositionality》，原思想是通过句子中的一个单词，预测上下文单词出现的概率，以最大化该概率为目标函数，学得每个单词的词向量。转移到图学习上来说，就是为每个用户或产品结点，根据其邻接关系信息学得（编码为）一个低维嵌入向量，用于推荐模型后续步骤。
  具体来说，GDRRSs先使用随机游走方法生成属于同一元路径的结点序列，然后利用Skip-gram模型（或类似模型）生成结点的低维嵌入向量（node representation）。该方法对同质图和异质图都可行。近年来，GDRRS以其简单、高效、高效的特点显示出了巨大的潜力。优点：简单、高效

#### 基于图神经嵌入的推荐系统（Graph Neural Embedding based RS (GNERS)）

  GNERS利用了神经网络，像多层感知机、自动编码器等，来学习用户或产品的embedding。图神经嵌入方法很容易和其他基础推荐模型（如基于RNN的）相结合以学习一个端到端（end to end）推荐系统。优点：容易和其他下游推荐模型集成，端到端训练，方便优化

### 图神经网络方法（GNN）

  图神经网络在图数据上应用神经网络技术。利用GNN在学习有用信息表达方面的优势，一些推荐系统模型已经使用GNN去解决图学习推荐系统的重要挑战。从模型的角度来看，主要分为3类：

#### 基于图注意力网络的推荐系统（GAT）

  GAT将注意力机制（attention mechanism）引入到GNN中，以有区别的学习不同的关系（relevance），以及给定图上不同其他用户（或项目）对目标用户的影响程度。在现实中，一个关系网中，并不是所有用户（或产品）节点都是同等重要的，而是一部分结点主要影响着局部的关系网；对某个具体的用户来说，他的所有朋友里，总有一些对其影响较大而有些影响甚微。所以有充足的理由将注意力机制应用到图神经网络中去。

#### 基于门控图神经网络的推荐系统（GGNN）

  GGNN将门控循环单元（Gated Recurrent Unit）引入到GNN中，通过迭代吸收图中图上其它结点的影响来全面地捕获结点间的关系，从而学得优化的结点表示（Representation，在推荐任务中通常就是embedding）。

相关文章：Session-based recommendation with graph neural networks

  作者提出SR-GNN,将session序列建模为图结构数据。在session图的基础上，GNN可以捕捉到items的复杂转换。每一个session利用注意力机制将整体偏好与当前偏好结合进行表示。

#### 基于图卷积网络的推荐系统（GCN）

  GCN一般学习如何利用图结构和结点特征信息从局部图上迭代地聚合邻居结点的特征信息。一般来说，通过卷积和池化操作，GCN能够有效学习用户和产品的信息嵌入，有效聚合来自图上邻居的信息。

### 知识图谱

知识图谱是表示大规模信息的实用方法，用节点代表实体，用边代表实体间的关系，由边形成的三元组（即，头部实体-关系-尾部实体）代表一条事实。由于节点和边类型多样，知识图谱是异质图，并可以用元路径/元图抽象出由多跳邻居构成的事实序列/子图的一般范式。

知识图谱作为辅助信息有两大优势：一是关系丰富，可以整合user、item、feature等多级异构关系于一体，尤其对于交互数据稀疏的场景，为提升推荐准确性带来了很多可能；二是关系明确，由于知识图谱里的关系已经显式构建好了，通过关系序列可以为推荐结果提供可解释性。



#### Reinforcement Learning over Sentiment-Augmented Knowledge Graphs towards Accurate and Explainable Recommendation

这一研究领域的许多工作都选择使用知识图(KG)，其中实体之间的关系可以作为解释。然而，现有的研究没有考虑KG中的关系情感，尽管有各种类型的关系情感值得考虑(例如，用户对某项物品的满意度)。在本文中，我们提出了一种新的基于KG和情感分析的推荐框架，使推荐更准确，解释更有说服力。为此，我们首先通过分析用户对商品的评论和评分，构建了一个情绪感知知识图(emotional - aware Knowledge Graph，即SAKG)。然后，我们通过我们提出的基于强化学习策略的情绪感知策略学习(即SAPL)对SAKG进行项目推荐和推理。为了提高终端用户的可解释性，我们进一步开发了一个交互式用户界面，提供文本解释以及与发现的情绪相关的评论集合。

